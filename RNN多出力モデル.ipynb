{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN多出力モデル.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/st-sashou/ai_experimental/blob/master/RNN%E5%A4%9A%E5%87%BA%E5%8A%9B%E3%83%A2%E3%83%87%E3%83%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "t2STDWzIhsGZ",
        "colab_type": "code",
        "outputId": "bdce7d34-9c9a-467e-f8a8-e724ff1e691b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7zhteHshhyfM",
        "colab_type": "code",
        "outputId": "416c1459-bed4-4bbc-bf09-c36db35efcf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "INPUT_FILE = \"/content/drive/My Drive/Colab Notebooks/ST/temperature_beverage_sales.csv\"\n",
        "\n",
        "df = pd.read_table(INPUT_FILE)\n",
        "df = df.set_index('date')\n",
        "df.tail()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temperature</th>\n",
              "      <th>sports_drink</th>\n",
              "      <th>soda</th>\n",
              "      <th>bottled_water</th>\n",
              "      <th>fruit_juice</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017/4/26</th>\n",
              "      <td>16.9</td>\n",
              "      <td>0.981085</td>\n",
              "      <td>0.753760</td>\n",
              "      <td>0.848250</td>\n",
              "      <td>0.747075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/4/27</th>\n",
              "      <td>14.7</td>\n",
              "      <td>0.854488</td>\n",
              "      <td>0.729856</td>\n",
              "      <td>0.732301</td>\n",
              "      <td>0.744117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/4/28</th>\n",
              "      <td>15.9</td>\n",
              "      <td>0.972824</td>\n",
              "      <td>0.944215</td>\n",
              "      <td>0.857018</td>\n",
              "      <td>0.699044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/4/29</th>\n",
              "      <td>16.2</td>\n",
              "      <td>0.853764</td>\n",
              "      <td>0.711245</td>\n",
              "      <td>0.875378</td>\n",
              "      <td>0.702002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017/4/30</th>\n",
              "      <td>17.8</td>\n",
              "      <td>0.955968</td>\n",
              "      <td>0.968912</td>\n",
              "      <td>1.149194</td>\n",
              "      <td>0.575005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           temperature  sports_drink      soda  bottled_water  fruit_juice\n",
              "date                                                                      \n",
              "2017/4/26         16.9      0.981085  0.753760       0.848250     0.747075\n",
              "2017/4/27         14.7      0.854488  0.729856       0.732301     0.744117\n",
              "2017/4/28         15.9      0.972824  0.944215       0.857018     0.699044\n",
              "2017/4/29         16.2      0.853764  0.711245       0.875378     0.702002\n",
              "2017/4/30         17.8      0.955968  0.968912       1.149194     0.575005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "IzH6KR2jiXE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "mms = MinMaxScaler()\n",
        "a = mms.fit_transform(df)\n",
        "df_norm = pd.DataFrame(a, index=df.index, columns=df.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrEDnSEO5RRY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generator(data, n_prev=10):\n",
        "    x, y= [], []\n",
        "    for i in range(len(data) - n_prev):\n",
        "#         print(data.iloc[i+n_prev:i+n_prev+1, 1:5])\n",
        "        x.append(data.temperature.iloc[i:i+n_prev].as_matrix()[:, np.newaxis])\n",
        "        y.append(data.iloc[i+n_prev:i+n_prev+1, 1:5].as_matrix())\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "X, Y = generator(df_norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOffxmFND3gB",
        "colab_type": "code",
        "outputId": "6e9ecd0f-3502-4b79-ea96-61f43a66d780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
        "Y_train = Y_train.transpose((2, 0, 1))\n",
        "Y_test = Y_test.transpose((2, 0, 1))\n",
        "Y_train = Y_train.reshape((Y_train.shape[0], Y_train.shape[1]))\n",
        "Y_test = Y_test.reshape((Y_test.shape[0], Y_test.shape[1]))\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(892, 10, 1)\n",
            "(4, 892)\n",
            "(224, 10, 1)\n",
            "(4, 224)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "WQm9e_ZxoC6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "cde5eb81-f804-4e29-acee-f150fbc78150"
      },
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.10576923],\n",
              "       [0.05769231],\n",
              "       [0.1025641 ],\n",
              "       [0.125     ],\n",
              "       [0.25961538],\n",
              "       [0.24679487],\n",
              "       [0.23397436],\n",
              "       [0.33653846],\n",
              "       [0.16666667],\n",
              "       [0.16987179]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "0YFfv0hJoPj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7126bb1-6d71-4ba7-f218-fc783c6b5bdb"
      },
      "cell_type": "code",
      "source": [
        "Y_train[0][0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06164472843163325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "o_0rCV8-ljb8",
        "colab_type": "code",
        "outputId": "3e5bdce8-5c47-428e-b861-87ebd2315e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "HIDDEN_SIZE = 16\n",
        "\n",
        "# 入力層、中間層\n",
        "input_layer = Input(shape=(10, 1))\n",
        "# x = SimpleRNN(LSTM, activation='relu', return_sequences=False, unroll=False)(x)\n",
        "x = LSTM(HIDDEN_SIZE)(input_layer)\n",
        "\n",
        "# 出力層\n",
        "output_layer1 = Dense(1, activation='linear', name='output_sports_drink')(x)\n",
        "output_layer2 = Dense(1, activation='linear', name='output_soda')(x)\n",
        "output_layer3 = Dense(1, activation='linear', name='output_bottled_water')(x)\n",
        "output_layer4 = Dense(1, activation='linear', name='output_fruit_juice')(x)\n",
        "\n",
        "model = Model(input_layer, [output_layer1, output_layer2, output_layer3, output_layer4])\n",
        "# model = Model(input_layer, output_layer1)\n",
        "model.compile(optimizer='rmsprop', loss='mape')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 10, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 16)           1152        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output_sports_drink (Dense)     (None, 1)            17          lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output_soda (Dense)             (None, 1)            17          lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output_bottled_water (Dense)    (None, 1)            17          lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "output_fruit_juice (Dense)      (None, 1)            17          lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,220\n",
            "Trainable params: 1,220\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QZQGn3C1wjvg",
        "colab_type": "code",
        "outputId": "aee2a3fc-6ec4-4096-9d14-03d3c4fa1780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1886
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train.tolist(), epochs=50, batch_size=16)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/50\n",
            "892/892 [==============================] - 1s 1ms/step - loss: 292696.9563 - output_sports_drink_loss: 81918.3903 - output_soda_loss: 83370.4603 - output_bottled_water_loss: 127357.4042 - output_fruit_juice_loss: 50.6940\n",
            "Epoch 2/50\n",
            "892/892 [==============================] - 0s 418us/step - loss: 202788.9710 - output_sports_drink_loss: 60360.3861 - output_soda_loss: 49528.5407 - output_bottled_water_loss: 92854.0565 - output_fruit_juice_loss: 45.9960\n",
            "Epoch 3/50\n",
            "892/892 [==============================] - 0s 411us/step - loss: 134421.3225 - output_sports_drink_loss: 53430.5290 - output_soda_loss: 29422.6404 - output_bottled_water_loss: 51523.3847 - output_fruit_juice_loss: 44.7660\n",
            "Epoch 4/50\n",
            "892/892 [==============================] - 0s 407us/step - loss: 84290.2504 - output_sports_drink_loss: 34442.3957 - output_soda_loss: 10758.1161 - output_bottled_water_loss: 39046.6269 - output_fruit_juice_loss: 43.1114\n",
            "Epoch 5/50\n",
            "892/892 [==============================] - 0s 407us/step - loss: 49892.8599 - output_sports_drink_loss: 30156.1998 - output_soda_loss: 15602.1945 - output_bottled_water_loss: 4093.8495 - output_fruit_juice_loss: 40.6157\n",
            "Epoch 6/50\n",
            "892/892 [==============================] - 0s 408us/step - loss: 20148.4238 - output_sports_drink_loss: 3684.9556 - output_soda_loss: 1332.6806 - output_bottled_water_loss: 15090.8847 - output_fruit_juice_loss: 39.9028\n",
            "Epoch 7/50\n",
            "892/892 [==============================] - 0s 413us/step - loss: 55422.8456 - output_sports_drink_loss: 24031.4425 - output_soda_loss: 11982.6446 - output_bottled_water_loss: 19370.0544 - output_fruit_juice_loss: 38.7055\n",
            "Epoch 8/50\n",
            "892/892 [==============================] - 0s 414us/step - loss: 22963.5709 - output_sports_drink_loss: 5517.6312 - output_soda_loss: 4499.0575 - output_bottled_water_loss: 12908.4797 - output_fruit_juice_loss: 38.4020\n",
            "Epoch 9/50\n",
            "892/892 [==============================] - 0s 423us/step - loss: 48796.1285 - output_sports_drink_loss: 11466.4053 - output_soda_loss: 18180.1469 - output_bottled_water_loss: 19111.4818 - output_fruit_juice_loss: 38.0961\n",
            "Epoch 10/50\n",
            "892/892 [==============================] - 0s 405us/step - loss: 18179.6694 - output_sports_drink_loss: 1283.8057 - output_soda_loss: 6468.6667 - output_bottled_water_loss: 10389.5208 - output_fruit_juice_loss: 37.6765\n",
            "Epoch 11/50\n",
            "892/892 [==============================] - 0s 411us/step - loss: 63282.8935 - output_sports_drink_loss: 21344.7106 - output_soda_loss: 27697.7937 - output_bottled_water_loss: 14202.8104 - output_fruit_juice_loss: 37.5764\n",
            "Epoch 12/50\n",
            "892/892 [==============================] - 0s 415us/step - loss: 23174.5765 - output_sports_drink_loss: 8972.9556 - output_soda_loss: 9142.6043 - output_bottled_water_loss: 5021.5160 - output_fruit_juice_loss: 37.5008\n",
            "Epoch 13/50\n",
            "892/892 [==============================] - 0s 404us/step - loss: 51652.7160 - output_sports_drink_loss: 13795.2633 - output_soda_loss: 23569.3402 - output_bottled_water_loss: 14251.1999 - output_fruit_juice_loss: 36.9125\n",
            "Epoch 14/50\n",
            "892/892 [==============================] - 0s 420us/step - loss: 9528.7403 - output_sports_drink_loss: 4669.8648 - output_soda_loss: 1547.1000 - output_bottled_water_loss: 3273.9354 - output_fruit_juice_loss: 37.8400\n",
            "Epoch 15/50\n",
            "892/892 [==============================] - 0s 399us/step - loss: 64243.0953 - output_sports_drink_loss: 22431.1423 - output_soda_loss: 12500.3356 - output_bottled_water_loss: 29274.3392 - output_fruit_juice_loss: 37.2781\n",
            "Epoch 16/50\n",
            "892/892 [==============================] - 0s 411us/step - loss: 24029.1533 - output_sports_drink_loss: 5733.1599 - output_soda_loss: 14527.2262 - output_bottled_water_loss: 3731.5659 - output_fruit_juice_loss: 37.2004\n",
            "Epoch 17/50\n",
            "892/892 [==============================] - 0s 408us/step - loss: 53258.5426 - output_sports_drink_loss: 21010.5452 - output_soda_loss: 11925.6885 - output_bottled_water_loss: 20285.2951 - output_fruit_juice_loss: 37.0133\n",
            "Epoch 18/50\n",
            "892/892 [==============================] - 0s 411us/step - loss: 21300.3269 - output_sports_drink_loss: 5870.3119 - output_soda_loss: 1960.9694 - output_bottled_water_loss: 13432.5325 - output_fruit_juice_loss: 36.5126\n",
            "Epoch 19/50\n",
            "892/892 [==============================] - 0s 410us/step - loss: 48994.5759 - output_sports_drink_loss: 13327.3638 - output_soda_loss: 24812.6024 - output_bottled_water_loss: 10817.5817 - output_fruit_juice_loss: 37.0294\n",
            "Epoch 20/50\n",
            "892/892 [==============================] - 0s 415us/step - loss: 21054.9757 - output_sports_drink_loss: 5644.9850 - output_soda_loss: 1114.2257 - output_bottled_water_loss: 14259.1375 - output_fruit_juice_loss: 36.6275\n",
            "Epoch 21/50\n",
            "892/892 [==============================] - 0s 404us/step - loss: 49825.7861 - output_sports_drink_loss: 16448.7276 - output_soda_loss: 8107.2776 - output_bottled_water_loss: 25232.3305 - output_fruit_juice_loss: 37.4497\n",
            "Epoch 22/50\n",
            "892/892 [==============================] - 0s 417us/step - loss: 4068.4429 - output_sports_drink_loss: 1053.8586 - output_soda_loss: 1680.9907 - output_bottled_water_loss: 1296.5373 - output_fruit_juice_loss: 37.0563\n",
            "Epoch 23/50\n",
            "892/892 [==============================] - 0s 405us/step - loss: 65475.8549 - output_sports_drink_loss: 9817.2764 - output_soda_loss: 19009.5176 - output_bottled_water_loss: 36612.4666 - output_fruit_juice_loss: 36.5925\n",
            "Epoch 24/50\n",
            "892/892 [==============================] - 0s 400us/step - loss: 17202.2974 - output_sports_drink_loss: 3907.8014 - output_soda_loss: 8213.6866 - output_bottled_water_loss: 5043.5892 - output_fruit_juice_loss: 37.2195\n",
            "Epoch 25/50\n",
            "892/892 [==============================] - 0s 429us/step - loss: 52454.3204 - output_sports_drink_loss: 20879.3449 - output_soda_loss: 14324.5655 - output_bottled_water_loss: 17213.4951 - output_fruit_juice_loss: 36.9165\n",
            "Epoch 26/50\n",
            "892/892 [==============================] - 0s 397us/step - loss: 21019.8524 - output_sports_drink_loss: 4352.3676 - output_soda_loss: 8438.5413 - output_bottled_water_loss: 8192.0678 - output_fruit_juice_loss: 36.8762\n",
            "Epoch 27/50\n",
            "892/892 [==============================] - 0s 406us/step - loss: 46146.6932 - output_sports_drink_loss: 13092.2057 - output_soda_loss: 9574.6626 - output_bottled_water_loss: 23442.4064 - output_fruit_juice_loss: 37.4178\n",
            "Epoch 28/50\n",
            "892/892 [==============================] - 0s 416us/step - loss: 26603.2420 - output_sports_drink_loss: 7285.0760 - output_soda_loss: 5179.5645 - output_bottled_water_loss: 14102.0145 - output_fruit_juice_loss: 36.5872\n",
            "Epoch 29/50\n",
            "892/892 [==============================] - 0s 400us/step - loss: 37534.8813 - output_sports_drink_loss: 6790.8688 - output_soda_loss: 28160.8598 - output_bottled_water_loss: 2546.3132 - output_fruit_juice_loss: 36.8415\n",
            "Epoch 30/50\n",
            "892/892 [==============================] - 0s 418us/step - loss: 31312.9361 - output_sports_drink_loss: 12694.8088 - output_soda_loss: 8175.1555 - output_bottled_water_loss: 10406.0729 - output_fruit_juice_loss: 36.8990\n",
            "Epoch 31/50\n",
            "892/892 [==============================] - 0s 412us/step - loss: 37156.9346 - output_sports_drink_loss: 7791.7339 - output_soda_loss: 15340.3734 - output_bottled_water_loss: 13987.8665 - output_fruit_juice_loss: 36.9607\n",
            "Epoch 32/50\n",
            "892/892 [==============================] - 0s 410us/step - loss: 31162.7115 - output_sports_drink_loss: 13764.7573 - output_soda_loss: 874.6548 - output_bottled_water_loss: 16486.2659 - output_fruit_juice_loss: 37.0338\n",
            "Epoch 33/50\n",
            "892/892 [==============================] - 0s 408us/step - loss: 37237.9067 - output_sports_drink_loss: 6285.8973 - output_soda_loss: 18399.3906 - output_bottled_water_loss: 12515.9325 - output_fruit_juice_loss: 36.6863\n",
            "Epoch 34/50\n",
            "892/892 [==============================] - 0s 414us/step - loss: 10481.5130 - output_sports_drink_loss: 8006.0456 - output_soda_loss: 923.0979 - output_bottled_water_loss: 1515.5757 - output_fruit_juice_loss: 36.7936\n",
            "Epoch 35/50\n",
            "892/892 [==============================] - 0s 400us/step - loss: 53566.5830 - output_sports_drink_loss: 9680.4101 - output_soda_loss: 20703.9937 - output_bottled_water_loss: 23145.7235 - output_fruit_juice_loss: 36.4537\n",
            "Epoch 36/50\n",
            "892/892 [==============================] - 0s 432us/step - loss: 35786.4854 - output_sports_drink_loss: 15810.6959 - output_soda_loss: 7685.7705 - output_bottled_water_loss: 12253.4896 - output_fruit_juice_loss: 36.5293\n",
            "Epoch 37/50\n",
            "892/892 [==============================] - 0s 403us/step - loss: 30999.0150 - output_sports_drink_loss: 4910.7897 - output_soda_loss: 25296.6587 - output_bottled_water_loss: 755.4156 - output_fruit_juice_loss: 36.1516\n",
            "Epoch 38/50\n",
            "892/892 [==============================] - 0s 403us/step - loss: 32749.3752 - output_sports_drink_loss: 12682.1646 - output_soda_loss: 8856.8223 - output_bottled_water_loss: 11173.6798 - output_fruit_juice_loss: 36.7078\n",
            "Epoch 39/50\n",
            "892/892 [==============================] - 0s 402us/step - loss: 19352.2242 - output_sports_drink_loss: 6416.8073 - output_soda_loss: 11143.8331 - output_bottled_water_loss: 1754.9461 - output_fruit_juice_loss: 36.6390\n",
            "Epoch 40/50\n",
            "892/892 [==============================] - 0s 402us/step - loss: 52895.1252 - output_sports_drink_loss: 13859.8864 - output_soda_loss: 6817.8371 - output_bottled_water_loss: 32181.1273 - output_fruit_juice_loss: 36.2761\n",
            "Epoch 41/50\n",
            "892/892 [==============================] - 0s 416us/step - loss: 25793.0731 - output_sports_drink_loss: 4972.7548 - output_soda_loss: 18658.8729 - output_bottled_water_loss: 2125.0307 - output_fruit_juice_loss: 36.4134\n",
            "Epoch 42/50\n",
            "892/892 [==============================] - 0s 411us/step - loss: 43195.8554 - output_sports_drink_loss: 16089.6690 - output_soda_loss: 6181.9321 - output_bottled_water_loss: 20888.2259 - output_fruit_juice_loss: 36.0282\n",
            "Epoch 43/50\n",
            "892/892 [==============================] - 0s 411us/step - loss: 24371.4224 - output_sports_drink_loss: 5572.5246 - output_soda_loss: 14703.7652 - output_bottled_water_loss: 4059.4517 - output_fruit_juice_loss: 35.6805\n",
            "Epoch 44/50\n",
            "892/892 [==============================] - 0s 408us/step - loss: 36583.7871 - output_sports_drink_loss: 9921.5151 - output_soda_loss: 13950.4619 - output_bottled_water_loss: 12674.5717 - output_fruit_juice_loss: 37.2387\n",
            "Epoch 45/50\n",
            "892/892 [==============================] - 0s 408us/step - loss: 32946.9190 - output_sports_drink_loss: 10793.6238 - output_soda_loss: 12255.6719 - output_bottled_water_loss: 9861.7925 - output_fruit_juice_loss: 35.8313\n",
            "Epoch 46/50\n",
            "892/892 [==============================] - 0s 407us/step - loss: 32814.0895 - output_sports_drink_loss: 7943.2041 - output_soda_loss: 6766.1761 - output_bottled_water_loss: 18068.1957 - output_fruit_juice_loss: 36.5138\n",
            "Epoch 47/50\n",
            "892/892 [==============================] - 0s 425us/step - loss: 33960.2840 - output_sports_drink_loss: 14141.4049 - output_soda_loss: 12493.3067 - output_bottled_water_loss: 7289.0977 - output_fruit_juice_loss: 36.4735\n",
            "Epoch 48/50\n",
            "892/892 [==============================] - 0s 403us/step - loss: 31905.3593 - output_sports_drink_loss: 4947.9668 - output_soda_loss: 16964.0525 - output_bottled_water_loss: 9956.3774 - output_fruit_juice_loss: 36.9641\n",
            "Epoch 49/50\n",
            "892/892 [==============================] - 0s 420us/step - loss: 29737.5104 - output_sports_drink_loss: 7417.4607 - output_soda_loss: 18879.3317 - output_bottled_water_loss: 3404.2091 - output_fruit_juice_loss: 36.5090\n",
            "Epoch 50/50\n",
            "892/892 [==============================] - 0s 406us/step - loss: 35570.2818 - output_sports_drink_loss: 7146.2092 - output_soda_loss: 3392.8164 - output_bottled_water_loss: 24994.1617 - output_fruit_juice_loss: 37.0943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fccd105c320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "pYLOrguR8h8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "26cb62dd-0b07-4548-e337-37b9afa7af90"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, Y_test.tolist())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "224/224 [==============================] - 0s 680us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7082.553022112165,\n",
              " 81.65472739083427,\n",
              " 120.87307739257812,\n",
              " 108.69351414271763,\n",
              " 6771.331451143537]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "yrJ7ys3liMg7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qFXqqmA9iRJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bdf9fd5b-81cd-43d3-8d3a-b84bae6bf1e5"
      },
      "cell_type": "code",
      "source": [
        "predicted = np.array(predicted)\n",
        "predicted.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 224, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "xfEzHD-ojWom",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted = predicted.transpose(1, 0, 2).reshape(224, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aKtEIL_Kji63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3999
        },
        "outputId": "d81fd227-0e8e-4b44-c8ec-5290c0a9d323"
      },
      "cell_type": "code",
      "source": [
        "for x, y in zip(predicted, Y_test.T):\n",
        "    print(x, y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.07931217 -0.17673294 -0.0841073   0.5073275 ] [0.76207303 0.79674753 0.75583167 0.78101185]\n",
            "[ 0.06641013 -0.15136842 -0.07186833  0.44453   ] [0.56504341 0.67965592 0.63583575 0.67271584]\n",
            "[ 0.0174689  -0.02495443 -0.01048756  0.11643426] [0.07449753 0.05368874 0.11261377 0.07047799]\n",
            "[ 0.04322221 -0.10255332 -0.04938421  0.32458973] [0.23896533 0.31700364 0.38887967 0.33515519]\n",
            "[ 0.06337633 -0.14709507 -0.07062664  0.43661565] [0.27459793 0.42651206 0.36557462 0.2783615 ]\n",
            "[0.00557955 0.00058397 0.00423031 0.0622383 ] [0.09387201 0.1324744  0.11356871 0.03633869]\n",
            "[0.00378032 0.01725461 0.01303009 0.00943275] [0.0804052  0.08463165 0.10437914 0.05872554]\n",
            "[ 0.01881596 -0.03121242 -0.01384726  0.13462925] [0.09731597 0.12430203 0.21143241 0.12918715]\n",
            "[ 0.01321156 -0.00357423  0.00039859  0.05272874] [0.07010496 0.08345643 0.15382706 0.16745202]\n",
            "[ 0.05144456 -0.12118669 -0.05854078  0.37100798] [0.39752579 0.51316068 0.55819422 0.58684741]\n",
            "[ 0.01811546 -0.04012493 -0.01724898  0.17023171] [0.06497102 0.08785457 0.10335227 0.08086857]\n",
            "[0.00552867 0.01079487 0.00929699 0.02628785] [0.07345531 0.07710281 0.14185651 0.12894181]\n",
            "[-0.00233781  0.02545331  0.01891617  0.00150869] [0.03625227 0.03084737 0.04851753 0.        ]\n",
            "[ 0.01949578 -0.02661435 -0.01242401  0.11480196] [0.1511309  0.234656   0.27952307 0.29493749]\n",
            "[0.00783202 0.01018482 0.00851249 0.0215585 ] [0.1196279  0.09919507 0.0971254  0.05397879]\n",
            "[ 0.05158805 -0.11954758 -0.05811712  0.36352348] [0.37083618 0.5948536  0.50782576 0.54689433]\n",
            "[0.00251426 0.01932679 0.01444212 0.00657489] [0.06918331 0.04512221 0.06541148 0.0448204 ]\n",
            "[ 0.05848287 -0.13817078 -0.06558674  0.41766268] [0.21769269 0.51938233 0.34716076 0.40360004]\n",
            "[ 0.05602601 -0.13064463 -0.06391526  0.39277673] [0.39073389 0.45859623 0.53920373 0.49838235]\n",
            "[0.00729611 0.01180254 0.00947547 0.01749662] [0.06972669 0.0536759  0.08852618 0.10213405]\n",
            "[ 0.05718039 -0.13683894 -0.06534793  0.41627747] [0.38920641 0.51210254 0.45425729 0.68048879]\n",
            "[ 0.03913084 -0.09687632 -0.04615883  0.31641388] [0.22147481 0.34290138 0.37192444 0.39177219]\n",
            "[ 0.04445146 -0.10729785 -0.05006659  0.34101343] [0.16008567 0.44206515 0.32392923 0.29898513]\n",
            "[ 0.04005207 -0.09457801 -0.04563664  0.30386657] [0.26117943 0.3479148  0.4191629  0.32746513]\n",
            "[ 0.04855897 -0.11771846 -0.05643349  0.36731327] [0.22896126 0.4257987  0.37682259 0.47866592]\n",
            "[ 0.05528538 -0.12634093 -0.06218493  0.3773725 ] [0.47606328 0.71014017 0.65754027 0.6669525 ]\n",
            "[ 0.00821156 -0.01389325 -0.0029518   0.10644384] [0.04676464 0.06566162 0.16964766 0.07848531]\n",
            "[ 0.03309354 -0.05764181 -0.02933565  0.1850087 ] [0.12313031 0.24538851 0.22497543 0.18736049]\n",
            "[ 0.05861365 -0.13827555 -0.06711772  0.41586018] [0.30378212 0.44373165 0.41833293 0.55590821]\n",
            "[ 0.0200674  -0.03366435 -0.01518705  0.13916713] [0.09310588 0.14661867 0.20280248 0.19601812]\n",
            "[ 0.02733073 -0.06867684 -0.03187755  0.24667706] [0.2263506  0.24587795 0.22237761 0.10599365]\n",
            "[ 0.04926428 -0.11792211 -0.05558952  0.36667585] [0.33026345 0.39349755 0.41430474 0.43175813]\n",
            "[ 0.04996593 -0.12222658 -0.05774529  0.38195437] [0.23186384 0.38218862 0.30283254 0.41989766]\n",
            "[ 0.03958361 -0.07380874 -0.03893683  0.22230335] [0.20194189 0.29662285 0.24361842 0.41012975]\n",
            "[ 0.06912828 -0.1548866  -0.07504568  0.44789857] [0.6070807  0.68864164 0.72323745 0.74141552]\n",
            "[ 0.01152186 -0.00075551  0.00198976  0.04753779] [0.0296455  0.02035566 0.03405321 0.08120561]\n",
            "[ 0.03915391 -0.08578771 -0.04229513  0.27171326] [0.11159209 0.17462659 0.23971542 0.1639952 ]\n",
            "[ 0.0548211  -0.13254261 -0.06236007  0.4075079 ] [0.30378405 0.41376853 0.37641705 0.496949  ]\n",
            "[ 0.02330696 -0.03821474 -0.01939921  0.14333397] [0.11003361 0.14740365 0.22222575 0.17209134]\n",
            "[0.00895146 0.00347296 0.00508386 0.04212382] [0.0328262  0.06294608 0.09656878 0.03038662]\n",
            "[ 0.02408921 -0.05016037 -0.02304544  0.18805848] [0.08303566 0.1422483  0.16745442 0.08913866]\n",
            "[0.00649101 0.00809685 0.00796742 0.03378126] [0.01558906 0.04657564 0.09390642 0.05873266]\n",
            "[ 0.0115101  -0.01276744 -0.00336619  0.09184514] [0.0835688  0.12038036 0.16445489 0.11700914]\n",
            "[ 0.01427256 -0.02954422 -0.01166538  0.14358042] [0.14004761 0.18428653 0.19810192 0.16652549]\n",
            "[ 0.06220798 -0.14370231 -0.06846376  0.42703718] [0.28805626 0.49896804 0.41076475 0.54257358]\n",
            "[ 0.02249813 -0.05249025 -0.02416838  0.20105092] [0.13122302 0.21832975 0.25472421 0.17442184]\n",
            "[ 0.00592006 -0.01068594 -0.00014937  0.1037306 ] [0.02407243 0.04656827 0.0579159  0.05920264]\n",
            "[ 0.01191957 -0.01519578 -0.00509815  0.09798585] [0.0417586  0.06160342 0.12785312 0.06148739]\n",
            "[ 0.08642646 -0.19093975 -0.09109385  0.54469264] [0.81834148 0.91447735 0.80414352 0.90610855]\n",
            "[ 0.01374518 -0.01681276 -0.00604867  0.09860478] [0.09410606 0.07821864 0.10477064 0.06592982]\n",
            "[ 0.0175915  -0.02673388 -0.01137629  0.12229459] [0.0734318  0.09883503 0.10836708 0.10104869]\n",
            "[ 0.08096441 -0.18061739 -0.0854087   0.5192096 ] [0.76539162 0.86973604 0.74528518 0.64632813]\n",
            "[ 0.05889502 -0.13650377 -0.06691333  0.4067291 ] [0.31850558 0.49193215 0.41795252 0.57029062]\n",
            "[ 0.04438379 -0.11257313 -0.05121236  0.36385798] [0.2785632  0.34679417 0.392106   0.41630415]\n",
            "[ 0.02503266 -0.04555517 -0.02059157  0.16875549] [0.01309114 0.04045683 0.07189563 0.06254704]\n",
            "[ 0.01424885 -0.01355074 -0.00480899  0.08467226] [0.14887274 0.18293426 0.1271807  0.12357979]\n",
            "[0.00594557 0.01197    0.01010299 0.02207779] [0.04103053 0.05774547 0.07924837 0.06625179]\n",
            "[ 0.04240287 -0.10021785 -0.04699577  0.3196954 ] [0.25292536 0.38364432 0.39250088 0.27339179]\n",
            "[ 0.01457282 -0.01248962 -0.00433388  0.08008035] [0.09523747 0.05704509 0.08613643 0.03053675]\n",
            "[ 0.02024234 -0.0447675  -0.01936831  0.1810832 ] [0.07889325 0.10462461 0.10979958 0.08506347]\n",
            "[ 0.01160937 -0.00391169  0.00062344  0.05899701] [0.06558187 0.08258322 0.07673298 0.06516068]\n",
            "[ 0.02778416 -0.04312547 -0.02260783  0.14704013] [0.17925409 0.21377862 0.21126064 0.17770517]\n",
            "[ 0.06513616 -0.14887401 -0.07293273  0.43610942] [0.41815499 0.58835395 0.4930074  0.4627272 ]\n",
            "[ 0.06073223 -0.14303793 -0.0682338   0.4294849 ] [0.32577447 0.58883987 0.45548818 0.45486392]\n",
            "[ 0.06079156 -0.14053917 -0.06934576  0.41644567] [0.3059905  0.51165887 0.44053294 0.55610789]\n",
            "[ 0.02260696 -0.0257888  -0.01345325  0.10010131] [0.10614984 0.16176161 0.20845376 0.14718638]\n",
            "[ 0.06094291 -0.1415295  -0.06830973  0.42149723] [0.31521727 0.46209371 0.40758006 0.54611456]\n",
            "[ 0.05227582 -0.12623656 -0.05908498  0.39077067] [0.23958423 0.33788066 0.34523131 0.36285765]\n",
            "[ 0.00868393 -0.00633174  0.00017417  0.07720935] [0.0230815  0.03259461 0.05223009 0.04857338]\n",
            "[ 0.0312694  -0.07160884 -0.03259718  0.24631907] [0.18344292 0.22217696 0.27981353 0.31913384]\n",
            "[ 0.03428577 -0.06882671 -0.03387827  0.2237248 ] [0.1440162  0.2444529  0.31697985 0.29454944]\n",
            "[ 0.03597252 -0.08267188 -0.03995409  0.27136296] [0.1032855  0.33542172 0.26000822 0.26624967]\n",
            "[ 0.07462425 -0.16495906 -0.08231554  0.4682446 ] [0.53630613 0.69071878 0.65059843 0.52603556]\n",
            "[ 0.01117846 -0.01281641 -0.00328402  0.09266539] [0.02926079 0.04096229 0.07927252 0.06115365]\n",
            "[ 0.03844326 -0.09076408 -0.0430408   0.29503608] [0.18853082 0.23874692 0.36896482 0.29328972]\n",
            "[0.00214728 0.01522575 0.01242696 0.02191684] [0.097826   0.12555601 0.09373005 0.04353611]\n",
            "[ 0.07034814 -0.15718704 -0.0779604   0.45148802] [0.44699684 0.55326947 0.50904459 0.63977873]\n",
            "[ 0.03928844 -0.09369466 -0.04404055  0.304047  ] [0.16411041 0.25321548 0.27613887 0.28203859]\n",
            "[ 0.0413611  -0.09754744 -0.04789795  0.3100235 ] [0.31325049 0.48267955 0.41036402 0.51856483]\n",
            "[ 0.01090692 -0.01003037 -0.00177828  0.08411275] [0.06233811 0.05501002 0.05732432 0.0708533 ]\n",
            "[ 0.07350095 -0.1694584  -0.07958577  0.49870837] [0.53701545 0.53644303 0.51149058 0.59832208]\n",
            "[ 0.0871456  -0.1925305  -0.09006774  0.5513238 ] [0.86112486 0.64290387 0.73310228 0.66352679]\n",
            "[ 0.0884471  -0.19275762 -0.09188696  0.54445064] [0.84681527 0.78989992 0.74600734 0.87226615]\n",
            "[ 0.01013255 -0.00900811 -0.00127639  0.08252323] [0.02589359 0.04150392 0.08844903 0.06386383]\n",
            "[ 0.07193793 -0.1660706  -0.07627329  0.49127322] [0.5186117  0.6018639  0.58059362 0.62305568]\n",
            "[0.00936681 0.00685297 0.00649724 0.02839661] [0.07390132 0.05720785 0.09190592 0.02597883]\n",
            "[ 0.0580443  -0.13429531 -0.06503017  0.4013371 ] [0.36848777 0.42863429 0.43072222 0.42467796]\n",
            "[ 0.06459757 -0.1486252  -0.07122093  0.43870687] [0.22042775 0.44698007 0.34835263 0.35586976]\n",
            "[0.00843264 0.00563934 0.00604225 0.03528036] [0.11714483 0.10455338 0.19320569 0.13234895]\n",
            "[0.00704393 0.00148229 0.00477506 0.05590986] [0.07091274 0.06961487 0.08075419 0.06743413]\n",
            "[ 0.08154447 -0.18355918 -0.08605662  0.53191596] [0.47652512 0.42729104 0.45699795 0.47112131]\n",
            "[0.00801651 0.00941039 0.00817917 0.02395841] [0.07669275 0.08063695 0.11248586 0.11110113]\n",
            "[ 0.04547524 -0.11689565 -0.05271871  0.37825167] [0.23653735 0.3195152  0.31494716 0.36637977]\n",
            "[ 0.05038291 -0.12270035 -0.05850347  0.38184333] [0.28721785 0.36665157 0.3847771  0.42336924]\n",
            "[0.00453157 0.00570224 0.00739569 0.04872807] [0.0411867  0.05898683 0.09593864 0.08550948]\n",
            "[ 0.05016731 -0.11086586 -0.05639543  0.33080757] [0.36738191 0.70539281 0.48352991 0.40592187]\n",
            "[ 0.02644064 -0.06411707 -0.02993463  0.23210265] [0.09198221 0.1697458  0.15782052 0.15003887]\n",
            "[ 0.0309334  -0.07652508 -0.03419188  0.26648408] [0.16952386 0.21903132 0.21192679 0.19562154]\n",
            "[ 0.03450793 -0.07650673 -0.03705883  0.25223666] [0.11134747 0.16001183 0.24616421 0.1741169 ]\n",
            "[ 0.05331849 -0.12703969 -0.06051937  0.3894112 ] [0.33754404 0.47311822 0.41662691 0.56333346]\n",
            "[ 0.07685383 -0.17329201 -0.0828907   0.5010446 ] [0.53186908 0.64366031 0.52406301 0.419347  ]\n",
            "[ 0.0403972  -0.08769184 -0.04385086  0.27430445] [0.30817208 0.31554073 0.39791417 0.44506172]\n",
            "[ 0.05157396 -0.12472059 -0.05988833  0.3852684 ] [0.22295092 0.32431545 0.32052721 0.35432441]\n",
            "[ 0.08719257 -0.1922448  -0.09088209  0.5487588 ] [0.86166152 0.65782346 0.71966043 0.60659684]\n",
            "[ 0.01204336 -0.01006135 -0.00248743  0.07987739] [0.10518542 0.11325326 0.0567588  0.11290792]\n",
            "[ 0.07807621 -0.1751248  -0.08397909  0.50438595] [0.81787494 0.90638786 0.87044451 0.65608063]\n",
            "[ 0.05829553 -0.13297488 -0.06567227  0.39373475] [0.38160343 0.44074392 0.47405447 0.51504539]\n",
            "[0.00254322 0.01229857 0.01095678 0.03135097] [0.0544269  0.06619054 0.03261    0.02222426]\n",
            "[0.00695928 0.01125609 0.0094401  0.02114583] [0.03855729 0.01361627 0.03115937 0.01617108]\n",
            "[ 0.05851557 -0.13029413 -0.06493402  0.3811953 ] [0.23161231 0.52533938 0.39316815 0.35575702]\n",
            "[0.00533066 0.01492168 0.01168244 0.01337798] [0.06409205 0.05371263 0.04954386 0.02669292]\n",
            "[ 0.07232391 -0.16589844 -0.0774261   0.48759842] [0.47035993 0.54900006 0.45697274 0.44399129]\n",
            "[ 0.02269712 -0.03892822 -0.01856687  0.14981005] [0.13505905 0.15692686 0.22610691 0.13068614]\n",
            "[ 0.08090458 -0.18250331 -0.08622801  0.5290072 ] [0.89770583 0.90522067 0.80850117 0.89051463]\n",
            "[ 0.06723102 -0.1538107  -0.0702635   0.45456916] [0.29260259 0.51652639 0.40058472 0.43261396]\n",
            "[ 0.0359084  -0.08972362 -0.0404595   0.30158913] [0.22393173 0.31721034 0.28388212 0.39506745]\n",
            "[ 0.05561381 -0.13170679 -0.06245866  0.40090668] [0.29236834 0.40900383 0.4013769  0.44557249]\n",
            "[ 0.0510385  -0.12046798 -0.05922931  0.36834127] [0.37759172 0.51404085 0.55124672 0.58290607]\n",
            "[ 0.0742883  -0.16957764 -0.07909535  0.49646997] [0.56351616 0.55095291 0.54030798 0.63163385]\n",
            "[ 0.03833    -0.07455909 -0.03770568  0.23121531] [0.16538356 0.19673077 0.20672243 0.317278  ]\n",
            "[ 0.02168809 -0.05217025 -0.02294298  0.20361088] [0.13211007 0.22330444 0.18145761 0.17108812]\n",
            "[ 0.01292565 -0.01391732 -0.00474579  0.08999899] [0.1255391  0.27263424 0.09029691 0.12386512]\n",
            "[ 0.05556555 -0.12944624 -0.06234568  0.390428  ] [0.39467932 0.52182565 0.50115988 0.567828  ]\n",
            "[ 0.055679   -0.12899378 -0.0629781   0.38722688] [0.25232009 0.38199449 0.37521297 0.37522269]\n",
            "[ 0.04413133 -0.1066705  -0.0503452   0.3390531 ] [0.15730853 0.4274552  0.28410553 0.31021654]\n",
            "[0.00888333 0.00278028 0.00460143 0.04431058] [0.05392757 0.08485561 0.11887639 0.07663424]\n",
            "[ 0.02588309 -0.04391382 -0.0218214   0.15688966] [0.07096165 0.08922296 0.14845792 0.09449921]\n",
            "[ 0.01897179 -0.03433907 -0.01597055  0.14422943] [0.17897728 0.30442674 0.33998204 0.3665564 ]\n",
            "[ 0.01582383 -0.02588434 -0.0103927   0.12546082] [0.1436076  0.16630305 0.0396382  0.07886816]\n",
            "[ 0.08170884 -0.1845988  -0.08472349  0.53816336] [0.56985355 0.46715633 0.51573499 0.47893053]\n",
            "[ 0.02291114 -0.05067277 -0.0233533   0.1930001 ] [0.12453008 0.16199309 0.23326443 0.19636437]\n",
            "[ 0.04620139 -0.10603116 -0.05152326  0.3279711 ] [0.27729676 0.37354957 0.39012608 0.51476696]\n",
            "[ 0.08665983 -0.18988086 -0.09158435  0.53718126] [0.86829476 0.79383882 0.78446072 0.83279793]\n",
            "[ 0.03973666 -0.09589989 -0.04619193  0.30993378] [0.17452506 0.32100289 0.33078712 0.37760693]\n",
            "[ 0.03014035 -0.06138962 -0.0307532   0.20814018] [0.06057598 0.22662267 0.22964965 0.14249348]\n",
            "[ 0.01393146 -0.02907361 -0.01154837  0.14257766] [0.11712811 0.11146408 0.16597274 0.12816751]\n",
            "[ 0.02797421 -0.0563248  -0.02734329  0.19702493] [0.14843163 0.11917916 0.21172522 0.17925653]\n",
            "[0.01081108 0.00240081 0.00386134 0.0393206 ] [0.09795874 0.09049538 0.17952175 0.11587894]\n",
            "[ 0.05093225 -0.11563282 -0.05752677  0.3487708 ] [0.32156942 0.56113283 0.4416059  0.53619078]\n",
            "[ 0.02841004 -0.06002445 -0.02784349  0.21142633] [0.1168633  0.27489913 0.32540578 0.32408288]\n",
            "[ 0.01860872 -0.02172031 -0.0098982   0.0998462 ] [0.08523569 0.10901083 0.08544509 0.08834524]\n",
            "[ 0.06457769 -0.14614439 -0.07292459  0.42521083] [0.48589805 0.73199046 0.55270117 0.46802307]\n",
            "[ 0.04408472 -0.10089093 -0.05067563  0.31290603] [0.17302907 0.26514487 0.34458662 0.25064157]\n",
            "[ 0.02594589 -0.04095684 -0.0206199   0.1459408 ] [0.07858738 0.08242319 0.08003068 0.07759479]\n",
            "[ 0.06089247 -0.1417182  -0.06833787  0.42246097] [0.3585582  0.5617917  0.47728139 0.52038157]\n",
            "[ 0.04017181 -0.09552635 -0.04653415  0.30660373] [0.18843951 0.25656995 0.34247193 0.28137769]\n",
            "[ 0.06463804 -0.14802296 -0.07095941  0.43611825] [0.55066757 0.6428333  0.58313679 0.65638981]\n",
            "[ 0.07456415 -0.17199543 -0.07932687  0.5078385 ] [0.64287968 0.75254728 0.63470175 0.41169437]\n",
            "[ 0.0439981  -0.09898165 -0.0498864   0.30560207] [0.20769395 0.54544263 0.35733749 0.30701322]\n",
            "[ 0.01307847 -0.01576845 -0.00494764  0.09798215] [0.06471975 0.06641157 0.11567841 0.09748058]\n",
            "[ 0.07584294 -0.16948234 -0.08125872  0.48741943] [0.48937418 0.66888937 0.54694131 0.53972761]\n",
            "[ 0.00709408 -0.01091285 -0.00164193  0.09854336] [0.11809747 0.12074981 0.17872921 0.06859805]\n",
            "[ 0.01948591 -0.02168547 -0.00977928  0.09762272] [0.09583108 0.14086831 0.20929622 0.19760449]\n",
            "[ 0.05860085 -0.13944371 -0.06418447  0.42462885] [0.3669148  0.47330847 0.43112499 0.49730906]\n",
            "[ 0.07338951 -0.16292676 -0.07962424  0.46600884] [0.37713395 0.4550208  0.43481036 0.57115185]\n",
            "[ 0.02197625 -0.04506465 -0.02116971  0.17481376] [0.17400578 0.16307324 0.2600632  0.20346881]\n",
            "[0.00245826 0.01307227 0.01133216 0.02883855] [0.08489384 0.06509065 0.06250054 0.04252173]\n",
            "[ 0.04418207 -0.10257746 -0.05060119  0.32001483] [0.31234574 0.48437444 0.41289975 0.51276543]\n",
            "[ 0.07794289 -0.17861012 -0.07992607  0.5275495 ] [0.50008406 0.5378076  0.48471398 0.57747447]\n",
            "[ 0.03425015 -0.07606331 -0.03794948  0.24986286] [0.12783554 0.22718241 0.30778252 0.22529916]\n",
            "[ 0.00809032 -0.01598188 -0.00417457  0.11365613] [0.08250017 0.15789825 0.19711829 0.20300099]\n",
            "[ 0.03289631 -0.06003672 -0.03084376  0.19363217] [0.10366953 0.32581961 0.30288556 0.19626207]\n",
            "[ 0.08552065 -0.19008608 -0.08666278  0.5487973 ] [0.64476166 0.52207611 0.57555882 0.50612411]\n",
            "[ 0.01609831 -0.02940564 -0.01155082  0.13810398] [0.09008762 0.09797589 0.11375045 0.08848107]\n",
            "[ 0.0786987  -0.17703791 -0.08492785  0.5109015 ] [0.73674342 0.58345964 0.63265582 0.54851132]\n",
            "[ 0.04343898 -0.10247926 -0.04949381  0.3234759 ] [0.22857566 0.32852542 0.35288134 0.30277984]\n",
            "[ 0.05356806 -0.12675646 -0.0596014   0.38806516] [0.13039759 0.24636009 0.23743293 0.24357469]\n",
            "[ 0.01272916 -0.02618989 -0.00893434  0.13764004] [0.03771575 0.13003067 0.10760679 0.13257664]\n",
            "[ 0.07333709 -0.16811666 -0.07889789  0.4932959 ] [0.43024223 0.61162987 0.55413091 0.40068579]\n",
            "[ 0.03530291 -0.0826918  -0.04058633  0.2725736 ] [0.16095762 0.25563447 0.32870836 0.29539351]\n",
            "[0.0068336  0.00834503 0.00769534 0.03051649] [0.04758648 0.05568017 0.07771394 0.0471921 ]\n",
            "[ 0.01078613 -0.00921591 -0.00153284  0.08133726] [0.07488511 0.07780786 0.08765044 0.09983755]\n",
            "[ 0.02215638 -0.05002239 -0.02358001  0.19240509] [0.17925317 0.21984184 0.24503218 0.23527874]\n",
            "[ 0.01455947 -0.02718347 -0.00957223  0.13613638] [0.00851153 0.04329556 0.0634942  0.0495371 ]\n",
            "[0.00326959 0.01739509 0.01334241 0.01116708] [0.01237552 0.02365352 0.07845988 0.01697535]\n",
            "[ 0.02524992 -0.05465727 -0.0249272   0.2011852 ] [0.0851608  0.11825249 0.12349267 0.09242417]\n",
            "[ 0.07602341 -0.16528478 -0.08320393  0.4633782 ] [0.68124837 0.58210205 0.69387851 0.61725528]\n",
            "[ 0.04899451 -0.11288227 -0.05656327  0.3438093 ] [0.32145007 0.59152186 0.47533891 0.41157684]\n",
            "[ 0.00895301 -0.0037783   0.00182467  0.06851111] [0.07501967 0.10023771 0.19377097 0.11502326]\n",
            "[ 0.06464422 -0.14871395 -0.07224546  0.43799794] [0.36023457 0.66048833 0.52913829 0.44353497]\n",
            "[ 0.05486576 -0.13015018 -0.06178391  0.39692026] [0.28424318 0.49104378 0.43913192 0.50221276]\n",
            "[ 0.018667   -0.03287594 -0.01482684  0.14057122] [0.06751636 0.08180283 0.1679886  0.07265069]\n",
            "[ 0.04959325 -0.12151982 -0.0559445   0.3817181 ] [0.27431141 0.36083516 0.35827386 0.38608542]\n",
            "[0.00163542 0.02153564 0.01581462 0.00185081] [0.00888259 0.02700064 0.08798512 0.03198643]\n",
            "[ 0.0603559  -0.13789785 -0.06812262  0.40675145] [0.55255698 0.70027112 0.60653809 0.70507808]\n",
            "[ 0.07591937 -0.17087223 -0.08032969  0.49525094] [0.5205819  0.51966616 0.54446038 0.52451262]\n",
            "[ 0.00996637 -0.00080813  0.00263521  0.05384117] [0.07739419 0.03280939 0.05614121 0.0213961 ]\n",
            "[ 0.01319962 -0.02006739 -0.00788266  0.11085466] [0.08059948 0.08581857 0.12984824 0.0591324 ]\n",
            "[ 0.03609511 -0.08501805 -0.03951931  0.281439  ] [0.09550147 0.30764904 0.18180884 0.24139008]\n",
            "[ 0.00773004 -0.00514074  0.00084663  0.07551837] [0.11130713 0.09324801 0.19074462 0.14325243]\n",
            "[ 0.03162268 -0.05389458 -0.02810185  0.17448962] [0.16386803 0.25037614 0.34956577 0.31075631]\n",
            "[ 0.01608329 -0.00945928 -0.00317557  0.06447272] [0.10759548 0.12121537 0.16789624 0.08204952]\n",
            "[ 0.0378722  -0.07382232 -0.03802577  0.22898798] [0.19736521 0.34229147 0.42040097 0.43981814]\n",
            "[ 0.0398487  -0.08505297 -0.04268707  0.26605904] [0.18588787 0.29554177 0.3818335  0.31182824]\n",
            "[ 0.01465807 -0.01195154 -0.00408386  0.0777612 ] [0.03918898 0.05418316 0.08509158 0.07500597]\n",
            "[ 0.04763583 -0.09996687 -0.05111043  0.296892  ] [0.29400828 0.28447718 0.2997371  0.26647964]\n",
            "[ 0.01974953 -0.03238214 -0.01446714  0.13629365] [0.10988907 0.14595802 0.06327788 0.09396466]\n",
            "[ 0.03255795 -0.07459779 -0.03563282  0.25152904] [0.2142948  0.32426909 0.22949917 0.14419537]\n",
            "[ 0.02694092 -0.06498224 -0.02977232  0.23461111] [0.09490622 0.1128135  0.18758442 0.09736672]\n",
            "[ 0.01583301 -0.02270095 -0.00795016  0.11563814] [0.04031343 0.06951361 0.12165346 0.08052131]\n",
            "[ 0.05879893 -0.13414444 -0.06609686  0.39689773] [0.48462297 0.56419581 0.65136345 0.64030801]\n",
            "[ 0.07755438 -0.17661902 -0.0812441   0.51726896] [0.57413782 0.77041361 0.6373685  0.46568251]\n",
            "[ 0.01399831 -0.01557129 -0.0057365   0.0929088 ] [0.09094383 0.13422934 0.16261231 0.13238978]\n",
            "[ 0.02990437 -0.05500429 -0.02801215  0.1844457 ] [0.18609786 0.29526697 0.33615559 0.3727629 ]\n",
            "[ 0.01292874 -0.0162522  -0.00554043  0.09909962] [0.07346428 0.07026417 0.0910299  0.0629531 ]\n",
            "[ 0.0047142  -0.00206331  0.00353706  0.07537813] [0.07738162 0.15577758 0.02342313 0.0529488 ]\n",
            "[ 0.02654539 -0.04042746 -0.01888631  0.14421655] [0.03426083 0.04837453 0.10153089 0.06579669]\n",
            "[ 0.07472236 -0.17006235 -0.08101128  0.49536794] [0.40858392 0.46567165 0.38876171 0.27571415]\n",
            "[ 0.06156376 -0.14363177 -0.06993627  0.4277159 ] [0.47905779 0.78727185 0.64147465 0.50205607]\n",
            "[ 0.03517121 -0.07890821 -0.03756125  0.2600457 ] [0.08986585 0.15203984 0.24000934 0.14543789]\n",
            "[ 0.02824568 -0.06350598 -0.03116173  0.22248201] [0.11933896 0.20767478 0.32837944 0.2537947 ]\n",
            "[ 0.04522937 -0.10787413 -0.05208474  0.33878475] [0.24320551 0.31823207 0.37551823 0.3980167 ]\n",
            "[0.00400656 0.01497036 0.01201893 0.01762379] [0.08323056 0.08212929 0.17373849 0.12459291]\n",
            "[ 0.02471195 -0.04442831 -0.02170372  0.16313861] [0.10888468 0.13826928 0.1627703  0.12869335]\n",
            "[ 0.04463217 -0.10627548 -0.05125196  0.3344912 ] [0.16394619 0.44848243 0.34440585 0.3281402 ]\n",
            "[ 0.05791778 -0.14046164 -0.06392432  0.4322425 ] [0.3329942  0.54984101 0.42610992 0.4329817 ]\n",
            "[ 0.03032355 -0.07252051 -0.03490629  0.250391  ] [0.21698622 0.22659191 0.22477373 0.16386551]\n",
            "[0.00473985 0.00719048 0.0080152  0.04277086] [0.06546653 0.06727777 0.05308616 0.01812388]\n",
            "[ 0.06061852 -0.14106546 -0.06932924  0.41957086] [0.61111198 0.77398768 0.68713697 0.58040957]\n",
            "[ 0.01082609 -0.00486841  0.00031235  0.06491445] [0.07945425 0.14123899 0.12292321 0.04414832]\n",
            "[ 0.03075908 -0.05800602 -0.02853673  0.19457605] [0.09687362 0.22566927 0.16376058 0.15322776]\n",
            "[ 0.03382754 -0.07364003 -0.0363157   0.24261503] [0.1338038  0.32198135 0.23612801 0.18086213]\n",
            "[ 0.02700782 -0.06431219 -0.0295231   0.23165943] [0.18610346 0.19566532 0.3079548  0.26601757]\n",
            "[0.00587816 0.01307807 0.01032252 0.01671537] [0.07741212 0.04458465 0.0670503  0.0367787 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "97ISXr1dmSs3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}